{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "from transformers import DebertaV2ForMultipleChoice, DebertaV2Tokenizer\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Data loading\n",
    "train_data = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/train.csv')\n",
    "extra_6000_data = pd.read_csv\\\n",
    "('/kaggle/input/additional-train-data-for-llm-science-exam/6000_train_examples.csv')\n",
    "extra_data = pd.read_csv\\\n",
    "('/kaggle/input/additional-train-data-for-llm-science-exam/extra_train_set.csv')\n",
    "\n",
    "# Combine all the datasets\n",
    "all_data = pd.concat([train_data, extra_6000_data, extra_data], ignore_index=True)\n",
    "\n",
    "# Data Preprocessing for all_data\n",
    "all_prompts = all_data['prompt'].tolist()\n",
    "all_choices = all_data[['A', 'B', 'C', 'D', 'E']].values.tolist()\n",
    "all_answers = [ord(a) - ord('A') for a in all_data['answer'].tolist()]\n",
    "\n",
    "all_data['A'].fillna('Unknown', inplace=True)\n",
    "all_data['B'].fillna('Unknown', inplace=True)\n",
    "all_data['C'].fillna('Unknown', inplace=True)\n",
    "all_data['D'].fillna('Unknown', inplace=True)\n",
    "all_data['E'].fillna('Unknown', inplace=True)\n",
    "\n",
    "all_choices = all_data[['A', 'B', 'C', 'D', 'E']].applymap(str).values.tolist()\n",
    "\n",
    "# Initialize the model and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model_path = '/kaggle/input/devertav3-large/kaggle/input/deberta_v3_large'\n",
    "model_path = '/kaggle/input/devertav3-large/kaggle/input/deberta_v3_large'\n",
    "model = DebertaV2ForMultipleChoice.from_pretrained(model_path, return_dict=True).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(model_path)\n",
    "\n",
    "all_input_ids_list = []\n",
    "all_attention_mask_list = []\n",
    "\n",
    "for i in range(len(all_prompts)):\n",
    "    prompt = all_prompts[i]\n",
    "    choice_list = all_choices[i]\n",
    "    prompt_choice_pairs = [(prompt, choice) for choice in choice_list]\n",
    "    # print(type(prompt), [type(choice) for choice in choice_list])\n",
    "\n",
    "    inputs = tokenizer.batch_encode_plus(\n",
    "        prompt_choice_pairs,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    all_input_ids_list.append(inputs[\"input_ids\"])\n",
    "    all_attention_mask_list.append(inputs[\"attention_mask\"])\n",
    "\n",
    "max_len = max(tensor.shape[1] for tensor in all_input_ids_list)\n",
    "padded_input_tensors = [F.pad(input=tensor, pad=(0, max_len - tensor.shape[1])) for tensor in all_input_ids_list]\n",
    "padded_attention_tensors = [F.pad(input=tensor, pad=(0, max_len - tensor.shape[1])) for tensor in all_attention_mask_list]\n",
    "\n",
    "all_input_ids = torch.stack(padded_input_tensors)\n",
    "all_attention_mask = torch.stack(padded_attention_tensors)\n",
    "all_labels = torch.tensor(all_answers, dtype=torch.long)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "# train_input_ids, val_input_ids, train_attention_mask, val_attention_mask, train_labels, val_labels = train_test_split(all_input_ids, all_attention_mask, all_labels, test_size=0.1, random_state=42)\n",
    "\n",
    "train_dataloader = DataLoader(TensorDataset(all_input_ids, all_attention_mask, all_labels), batch_size=2, shuffle=True)\n",
    "# val_dataloader = DataLoader(TensorDataset(val_input_ids, val_attention_mask, val_labels), batch_size=2, shuffle=False)\n",
    "\n",
    "\n",
    "best_map3 = 0.0  # Initialize best MAP@3\n",
    "\n",
    "# Fine-tuning with validation\n",
    "def fine_tune_and_validate(model, train_dataloader, epochs=5):\n",
    "    global best_map3\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Starting epoch {epoch+1}\")\n",
    "        \n",
    "        # Training\n",
    "        model.train()\n",
    "        for batch in tqdm(train_dataloader):\n",
    "            input_ids, attention_mask, labels = [t.to(device) for t in batch]\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "#         # Validation\n",
    "#         model.eval()\n",
    "#         all_scores = []\n",
    "#         all_labels = []\n",
    "#         with torch.no_grad():\n",
    "#             for batch in tqdm(val_dataloader):\n",
    "#                 input_ids, attention_mask, labels = [t.to(device) for t in batch]\n",
    "#                 outputs = model(input_ids, attention_mask=attention_mask)[0]\n",
    "#                 scores = torch.softmax(outputs, dim=1)\n",
    "#                 all_scores.append(scores.cpu().numpy())\n",
    "#                 all_labels.append(labels.cpu().numpy())\n",
    "        \n",
    "#         all_scores = np.concatenate(all_scores, axis=0)\n",
    "#         all_labels = np.concatenate(all_labels, axis=0)\n",
    "        \n",
    "#         map3 = label_ranking_average_precision_score(all_labels, all_scores)\n",
    "#         print(f\"Validation MAP@3 for epoch {epoch+1}: {map3}\")\n",
    "        \n",
    "#         if map3 > best_map3:\n",
    "#             print(\"New best model. Saving...\")\n",
    "#             best_map3 = map3\n",
    "            \n",
    "    return model\n",
    "\n",
    "# Fine-tuning the model\n",
    "model = fine_tune_and_validate(model, train_dataloader, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DebertaV2ForMultipleChoice, DebertaV2Tokenizer, DebertaV2Config\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# 데이터 로드\n",
    "# data = pd.read_csv('data/train.csv')\n",
    "data = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/test.csv')\n",
    "\n",
    "\n",
    "# 데이터 전처리\n",
    "prompts = data['prompt'].tolist()\n",
    "choices = data[['A', 'B', 'C', 'D', 'E']].values.tolist()\n",
    "# answers = [ord(a) - ord('A') for a in data['answer'].tolist()]\n",
    "\n",
    "# Update the tokenization step\n",
    "input_ids_list = []\n",
    "attention_mask_list = []\n",
    "for i in range(len(prompts)):\n",
    "    prompt = prompts[i]\n",
    "    choice_list = choices[i]\n",
    "    # Creating a list of 5 pairs: each prompt-choice pair as a tuple\n",
    "    prompt_choice_pairs = [(prompt, choice) for choice in choice_list]\n",
    "    \n",
    "    inputs = tokenizer.batch_encode_plus(\n",
    "        prompt_choice_pairs,\n",
    "        padding=True, \n",
    "        truncation=True, \n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    input_ids_list.append(inputs[\"input_ids\"])\n",
    "    attention_mask_list.append(inputs[\"attention_mask\"])\n",
    "\n",
    "# Step 1: Determine max length\n",
    "max_length = 0\n",
    "for ids in input_ids_list:\n",
    "    max_length = max(max_length, ids.size(1))\n",
    "\n",
    "# Step 2: Pad each tensor to max length\n",
    "padded_input_ids_list = []\n",
    "padded_attention_mask_list = []\n",
    "for ids, mask in zip(input_ids_list, attention_mask_list):\n",
    "    padding_length = max_length - ids.size(1)\n",
    "    \n",
    "    # Pad input_ids\n",
    "    padded_ids = torch.cat([\n",
    "        ids, \n",
    "        torch.zeros((ids.size(0), padding_length), dtype=ids.dtype)\n",
    "    ], dim=1)\n",
    "    padded_input_ids_list.append(padded_ids)\n",
    "    \n",
    "    # Pad attention_mask\n",
    "    padded_mask = torch.cat([\n",
    "        mask,\n",
    "        torch.zeros((mask.size(0), padding_length), dtype=mask.dtype)\n",
    "    ], dim=1)\n",
    "    padded_attention_mask_list.append(padded_mask)\n",
    "\n",
    "# Step 3: Stack the tensors\n",
    "input_ids = torch.stack(padded_input_ids_list)\n",
    "attention_mask = torch.stack(padded_attention_mask_list)\n",
    "\n",
    "# DataLoader 생성을 위한 수정\n",
    "dataset = TensorDataset(input_ids, attention_mask)  # answers 부분이 제거됨\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=False)  # shuffle을 False로 설정\n",
    "\n",
    "# 예측 결과를 저장할 DataFrame 생성\n",
    "submission_data = []\n",
    "\n",
    "# 예측 함수 정의\n",
    "def predict(model, dataloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in tqdm(enumerate(dataloader)):\n",
    "            input_ids, attention_mask = batch\n",
    "\n",
    "            # 텐서를 GPU로 이동\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)[0]\n",
    "            scores = torch.softmax(outputs, dim=1)\n",
    "            \n",
    "            # GPU에서 CPU로 데이터를 이동하고 NumPy 배열로 변환\n",
    "            scores = scores.cpu().numpy()\n",
    "\n",
    "            for i in range(scores.shape[0]):  # 추가: 각 배치에 있는 모든 샘플에 대한 예측을 수행\n",
    "                pred_scores = scores[i]\n",
    "                sorted_indices = pred_scores.argsort()[::-1][:3]\n",
    "                sorted_choices = \" \".join([chr(ord('A') + j) for j in sorted_indices])\n",
    "                actual_id = idx * dataloader.batch_size + i  # 실제 데이터 샘플의 id 계산\n",
    "                submission_data.append([actual_id, sorted_choices])\n",
    "\n",
    "# 예측 수행\n",
    "predict(model, dataloader)\n",
    "\n",
    "# submission.csv 파일로 저장\n",
    "submission_df = pd.DataFrame(submission_data, columns=['id', 'prediction'])\n",
    "# submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "# # 'id' 열을 DataFrame의 인덱스로 설정\n",
    "# submission_df.set_index('id', inplace=True)\n",
    "\n",
    "# CSV 파일로 저장 (이번에는 index=True)\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
